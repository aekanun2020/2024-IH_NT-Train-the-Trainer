{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fa52606-b322-462f-ac64-7f2ba96113b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31aeff10-f4b6-4025-9267-e007a1367ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### กำหนด data type ที่เหมาะสมกับ attribute values (Custom data types) ###\n",
    "\n",
    "\n",
    "def guess_column_types(file_path, delimiter=',', has_headers=True):\n",
    "    try:\n",
    "        # Read the CSV file using the specified delimiter and header settings\n",
    "        df = pd.read_csv(file_path, sep=delimiter,low_memory=False, header=0 if has_headers else None)\n",
    "\n",
    "        # Initialize a dictionary to store column data types\n",
    "        column_types = {}\n",
    "\n",
    "        # Loop through columns and infer data types\n",
    "        for column in df.columns:\n",
    "            # sample_values = df[column].dropna().sample(min(5, len(df[column])), random_state=42)\n",
    "\n",
    "            # Check for datetime format \"YYYY-MM-DD HH:MM:SS\"\n",
    "            is_datetime = all(re.match(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}', str(value)) for value in df[column])\n",
    "\n",
    "            # Check for date format \"YYYY-MM-DD\"\n",
    "            is_date = all(re.match(r'\\d{4}-\\d{2}-\\d{2}', str(value)) for value in df[column])\n",
    "\n",
    "            # Assign data type based on format detection\n",
    "            if is_datetime:\n",
    "                inferred_type = 'datetime64'\n",
    "            elif is_date:\n",
    "                inferred_type = 'date'\n",
    "            else:\n",
    "                inferred_type = pd.api.types.infer_dtype(df[column], skipna=True)\n",
    "\n",
    "            column_types[column] = inferred_type\n",
    "\n",
    "        return (True, column_types)  # Return success and column types\n",
    "    except pd.errors.ParserError:\n",
    "        return (False, str(e))  # Return error message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7620bebc-230f-48ba-8349-f98a595d2d73",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './LoanStats_web.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./LoanStats_web.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m result, column_types_or_error \u001b[38;5;241m=\u001b[39m \u001b[43mguess_column_types\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn Types:\u001b[39m\u001b[38;5;124m\"\u001b[39m, column_types_or_error)\n",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m, in \u001b[0;36mguess_column_types\u001b[0;34m(file_path, delimiter, has_headers)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mguess_column_types\u001b[39m(file_path, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, has_headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;66;03m# Read the CSV file using the specified delimiter and header settings\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m         df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelimiter\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhas_headers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;66;03m# Initialize a dictionary to store column data types\u001b[39;00m\n\u001b[1;32m     10\u001b[0m         column_types \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/inclass/lib/python3.8/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/inclass/lib/python3.8/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/inclass/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/inclass/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/inclass/lib/python3.8/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './LoanStats_web.csv'"
     ]
    }
   ],
   "source": [
    "file_path = './LoanStats_web.csv'\n",
    "result, column_types_or_error = guess_column_types(file_path)\n",
    "\n",
    "if result:\n",
    "    print(\"Column Types:\", column_types_or_error)\n",
    "else:\n",
    "    print(\"Error:\", column_types_or_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58643a4d-b8c9-4d07-a4c1-9041e3723967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# เปลี่ยน data type บางตัว ให้เหมาะสมกับ python's environment และ MSSQL\n",
    "column_types_corrected = {col: ('datetime64' if t == 'date' else 'float64' if t == 'floating' else t) \\\n",
    "                          for col, t in column_types_or_error.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3949840e-4a31-463c-a231-09851918c3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### นำ dictionary ที่บรรจุ ชื่อ col และ data type มาใช้เป็น parameter ของการทำ pd.read_csv ( ) อ่าน csv มาเป็น dataframe ###\n",
    "raw_df = pd.read_csv(file_path, dtype=column_types_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b250049-12b4-470c-9c2e-ebd2ffec65da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# คำนวน percentage ของ missing values ของแต่ละ col. ใน dataframe (raw_df)\n",
    "missing_percentage = raw_df.isnull().mean() * 100\n",
    "\n",
    "# กรอง columns ที่มี null เกินกว่า 30% ออกไป\n",
    "columns_to_keep = missing_percentage[missing_percentage <= 30].index.tolist()\n",
    "filteredCol_df = raw_df[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af877ac2-8d64-4fe8-8c3b-c0fa8fd3cdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = filteredCol_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f07f82-0cd4-4efa-be88-006dc75430aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce5cf40-8860-4eb1-86ca-8e93f99ce1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc44308a-b875-4b31-812c-684c03ee1694",
   "metadata": {},
   "outputs": [],
   "source": [
    "acceptableMax_null = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf66f2cc-2c37-42d2-a9cd-162e6ac6ebd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# สร้างรายการของคอลัมน์ที่มี Non-Null จำนวน 1,432,440\n",
    "## selected_columns = [col for col in raw_df.columns if raw_df[col].notnull().sum() == 1432440]\n",
    "selected_columns = [col for col in raw_df.columns if raw_df[col].isnull().sum() <= acceptableMax_null]\n",
    "\n",
    "# แสดงคอลัมน์ที่เลือก\n",
    "print(\"Selected columns:\", selected_columns)\n",
    "\n",
    "# สร้าง DataFrame ใหม่จากคอลัมน์ที่เลือก\n",
    "df_selected = raw_df[selected_columns]\n",
    "\n",
    "\n",
    "# ลบแถวที่มีค่า null ในคอลัมน์เหล่านั้น\n",
    "noNull_df = df_selected.dropna()\n",
    "\n",
    "# แสดงข้อมูลทั่วไปของ DataFrame หลังจากลบ null\n",
    "noNull_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f21c105-e767-40d7-9f25-847e365e6a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ทำสำเนาตัวแปร โดยหลังจากนี้ หากเกิดความเปลี่ยนแปลงกับ ตัวแปรใหม่ (df_prepared) จะไม่ส่งผลใดๆ ต่อตัวแปรเดิม (noNull_df)\n",
    "df_prepared = noNull_df.copy()\n",
    "\n",
    "# เปลี่ยน data type เป็น datetime สำหรับ col: issue_d\n",
    "df_prepared['issue_d'] = pd.to_datetime(df_prepared['issue_d'], format='%b-%Y')\n",
    "\n",
    "# นำเครื่องหมาย % ออกจากค่าใน col: int_rate แล้วเปลี่ยน data type เป็น float\n",
    "if df_prepared['int_rate'].dtype == 'string':\n",
    "    df_prepared['int_rate'] = df_prepared['int_rate'].str.rstrip('%').astype('float') / 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31f65e8-ab96-4987-9a39-ae6dded7ec2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prepared.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b24337-986d-41d1-9740-73fc7daca158",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prepared.groupby('issue_d').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a493ae6-7be9-47b5-8f95-890e403e85d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prepared.groupby('int_rate').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23ea9e4-f5f8-4f6c-90f0-3c166640fc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "## dimension table เป็นสิ่งที่อยู่ใน data warehouse ไม่ใช่ python\n",
    "## แต่เราจะใช้ python ไป create dim. table ใน data warehouse พร้อม insert ข้อมูลลงไปด้วย\n",
    "## ด้วยเหตุนี้ ครูเอ้จึงเสนอ idea สำหรับการใช้ python พัฒนา dim. table ดังนี้\n",
    "## (1) สร้าง dataframe ขึ้นมาใหม่ เพื่อทำหน้าที่เป็น dim. table โดยมีเฉพาะ col. ตาม dimensional model ที่ออกแบบไว้แล้ว\n",
    "## (2) สร้าง col. ใหม่ขึ้นมาบน dataframe ข้อ (1) เพื่อจะใช้เป็น primary key สำหรับ dim. table\n",
    "\n",
    "# ทำข้อ (1) สำหรับ home_ownership\n",
    "home_ownership_dim = df_prepared[['home_ownership']].drop_duplicates().reset_index(drop=True)\n",
    "home_ownership_dim.reset_index(inplace=True)\n",
    "# ทำข้อ (2) สำหรับ home_ownership\n",
    "home_ownership_dim['home_ownership_id'] = home_ownership_dim.index\n",
    "\n",
    "# ทำข้อ (1) สำหรับ loan_status\n",
    "loan_status_dim = df_prepared[['loan_status']].drop_duplicates().reset_index(drop=True)\n",
    "loan_status_dim.reset_index(inplace=True)\n",
    "# ทำข้อ (2) สำหรับ loan_status\n",
    "loan_status_dim['loan_status_id'] = loan_status_dim.index\n",
    "\n",
    "# ทำข้อ (1) สำหรับ สำหรับ issue_d\n",
    "issue_d_dim = df_prepared[['issue_d']].drop_duplicates().reset_index(drop=True)\n",
    "issue_d_dim['month'] = issue_d_dim['issue_d'].dt.month\n",
    "issue_d_dim['year'] = issue_d_dim['issue_d'].dt.year\n",
    "issue_d_dim.reset_index(inplace=True)\n",
    "# ทำข้อ (2) สำหรับ สำหรับ issue_d\n",
    "issue_d_dim['issue_d_id'] = issue_d_dim.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99f2e80-818e-4d2d-a45b-fcdda0ed2c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "issue_d_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa572a0-39c8-493f-89cb-923ca0eb94ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_status_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77963613-62ca-4ade-9002-5214ea63fb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_ownership_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fca20fd-e2b1-4a44-8ff2-b2d193bf758f",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_ownership_dim.set_index('home_ownership')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a262a5-0aad-476a-a49d-dd0f02d02e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_ownership_dim.set_index('home_ownership')['home_ownership_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ca5f9d-a386-4524-b6cf-ed922131ff4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_ownership_dim.set_index('home_ownership')['home_ownership_id'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ae7445-b214-45ee-90d9-bb01d621a5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_status_dim.set_index('loan_status')['loan_status_id'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e9c049-2b3d-4688-8936-09f865dc3ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "issue_d_dim.set_index('issue_d')['issue_d_id'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86d7020-a6ab-4222-9613-43f1ec7ddc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "## fact table เป็นสิ่งที่อยู่ใน data warehouse ไม่ใช่ python\n",
    "## แต่เราจะใช้ python ไป create fact table ใน data warehouse พร้อม insert ข้อมูลลงไปด้วย\n",
    "## ด้วยเหตุนี้ ครูเอ้จึงเสนอ idea สำหรับการใช้ python พัฒนา fact table ดังนี้\n",
    "## (1) สร้าง python's dict. ขึ้นมาใช้ key mapping (สร้าง foreign key ของ fact table ตรงกับ primary key ของ dim. table)\n",
    "## (2) dataframe ขึ้นมาใหม่ เพื่อทำหน้าที่เป็น fact table โดยนำ key mapping ตามข้อ 1 มาใช้ด้วย"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fb3b04-13d4-45e6-9373-1476bf2d36cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ทำข้อ (1)\n",
    "home_ownership_map = home_ownership_dim.set_index('home_ownership')['home_ownership_id'].to_dict()\n",
    "loan_status_map = loan_status_dim.set_index('loan_status')['loan_status_id'].to_dict()\n",
    "issue_d_map = issue_d_dim.set_index('issue_d')['issue_d_id'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad0bfce-7319-4f79-8d8f-611f6ab8bf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ทำข้อ (2)\n",
    "loans_fact = df_prepared.copy()\n",
    "loans_fact['home_ownership_id'] = loans_fact['home_ownership'].map(home_ownership_map)\n",
    "loans_fact['loan_status_id'] = loans_fact['loan_status'].map(loan_status_map)\n",
    "loans_fact['issue_d_id'] = loans_fact['issue_d'].map(issue_d_map)\n",
    "\n",
    "# เลือกคอลัมน์ที่จำเป็นสำหรับ Fact Table\n",
    "loans_fact = loans_fact[['application_type','loan_amnt', 'funded_amnt', 'term', 'int_rate', 'installment'\\\n",
    "                         , 'home_ownership_id', 'loan_status_id', 'issue_d_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e596109a-797f-4151-b4b7-f5d0db9604de",
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_fact.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ad2eb6-f627-47e4-8582-62b33d945b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5839273c-707d-42ee-927c-5a39f443a7f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144f9cce-c8aa-4038-8ce2-5ffcf8503b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "### เริ่มต้นเปลี่ยนเป็น raw cell ชั่วคราว ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427bfbee-8f08-40ca-9209-5b5fbce331e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## [optional] ทดสอบการ join ทุก dataframe ทั้ง fact และ dim. เข้าด้วยกัน\n",
    "\n",
    "# Join `loans_fact` กับ `home_ownership_dim` โดยใช้ 'home_ownership_id'\n",
    "loans_fact_with_home_ownership = pd.merge(loans_fact, home_ownership_dim, on='home_ownership_id', how='left', suffixes=('', '_home_ownership'))\n",
    "\n",
    "# Join ผลลัพธ์กับ `loan_status_dim` โดยใช้ 'loan_status_id'\n",
    "loans_fact_with_home_ownership_with_loan_status = pd.merge(loans_fact_with_home_ownership, loan_status_dim, on='loan_status_id', how='left', suffixes=('', '_loan_status'))\n",
    "\n",
    "# Join ผลลัพธ์กับ `issue_d_dim` โดยใช้ 'issue_d_id'\n",
    "final_df = pd.merge(loans_fact_with_home_ownership_with_loan_status, issue_d_dim, on='issue_d_id', how='left', suffixes=('', '_issue_d'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88389a4-419a-49ac-aae9-ad9022880bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## [optional] ผลลัพธ์จากการ join คือ final_df ต้องมี row เท่ากันกับ dataframe เดิม\n",
    "print(f\"จำนวนแถวใน noNull_df: {noNull_df.shape[0]}\")\n",
    "print(f\"จำนวนแถวใน final_df: {final_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fc3a55-2f50-4976-9682-36905df29046",
   "metadata": {},
   "outputs": [],
   "source": [
    "## [optional] ผลลัพธ์จากการ join คือ final_df ต้องมีค่าของ measure เท่ากันกับ dataframe เดิม\n",
    "print(\"การเปรียบเทียบค่า loan_amnt จาก dataframe เดิม กับ fact:\")\n",
    "print(noNull_df['funded_amnt'].head())\n",
    "print(final_df['funded_amnt'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae8f6f7-a0c6-4860-8734-3d52d9d02f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## [optional] ผลลัพธ์จากการ join คือ final_df ต้องไม่มี NULL เลย\n",
    "print(\"จำนวนค่า Null ใน final_df หลังจากการ join:\")\n",
    "print(final_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d435e267-0ee2-42d4-af2f-804aff839236",
   "metadata": {},
   "outputs": [],
   "source": [
    "### สิ้นสุดเปลี่ยนเป็น raw cell ชั่วคราว ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42400a1d-19d7-4448-99b3-db2b1cab4f4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb656a0-57a8-4845-b843-4a6063fb37fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060ec76a-3181-4a9d-b0b7-c775c329cc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "server = '34.136.225.236'\n",
    "database = 'loanDW'\n",
    "username = 'SA'\n",
    "password = 'Passw0rd123456'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3038eca1-0e0f-4c54-8c26-07e2e6fe0dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "issue_d_dim.drop(columns=['index'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0a214e-3dc5-463e-8b14-49e54b45d735",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_status_dim.drop(columns=['index'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947e9cac-4ce8-4ac1-95e9-16173cc49aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_ownership_dim.drop(columns=['index'], inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9200568f-7659-4429-8488-a9d5ebbb3ca2",
   "metadata": {},
   "source": [
    "from sqlalchemy import create_engine\n",
    "import urllib\n",
    "\n",
    "# ตั้งค่าการเชื่อมต่อกับ MSSQL โดยใช้ข้อมูลที่เหมาะสมกับสภาพแวดล้อมของคุณ\n",
    "params = urllib.parse.quote_plus(\"DRIVER={ODBC Driver 17 for SQL Server};SERVER=server;DATABASE=database;UID=username;PWD=password\")\n",
    "##### engine = create_engine(f\"mssql+pyodbc:///?odbc_connect={params}\")\n",
    "# Using pymssql\n",
    "engine = create_engine(f'mssql+pymssql://{username}:{password}@{server}/{database}')\n",
    "\n",
    "\n",
    "# นำเข้าข้อมูล Dimension Tables ไปยัง MSSQL ให้ตรงกับขั้นตอนการเตรียมข้อมูลที่คุณทำไว้\n",
    "##### home_ownership_dim.to_sql('home_ownership_dim', con=engine, if_exists='replace', index=True, index_label='home_ownership_id')\n",
    "##### loan_status_dim.to_sql('loan_status_dim', con=engine, if_exists='replace', index=True, index_label='loan_status_id')\n",
    "\n",
    "home_ownership_dim.to_sql('home_ownership_dim', con=engine, if_exists='replace', index=False)\n",
    "loan_status_dim.to_sql('loan_status_dim', con=engine, if_exists='replace', index=False)\n",
    "issue_d_dim.to_sql('issue_d_dim', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "\n",
    "\n",
    "# นำเข้าข้อมูล Fact Table ไปยัง MSSQL โดยใช้ข้อมูลที่เตรียมไว้\n",
    "loans_fact.to_sql('loans_fact', con=engine, if_exists='replace', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb1e07a-4b7b-4023-8128-cc3326d05b97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37d80f5-7868-42e8-9b1b-34ffd2b1b3b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a01cc5b-a808-4d12-9ede-4bc1f1a43f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
